{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCLSjKk2qWvd"
   },
   "source": [
    "## Basics of prompting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is prompting?\n",
    "\n",
    "A prompt is a natural language request submitted to a language model to receive a response back. \n",
    "\n",
    "### What is a prompt made of?\n",
    "\n",
    "Prompts can contain questions, instructions, contextual information, few-shot examples, and partial input for the model to complete or continue.\n",
    "\n",
    "### Components of a prompt\n",
    "\n",
    "- Task (required)\n",
    "- System instructions (optional)\n",
    "- Few-shot examples (optional)\n",
    "- Contextual information (optional)\n",
    "\n",
    "1) **Task**: A task is the text in the prompt that you want the model to provide a response for. \n",
    "\n",
    "<div style=\"border: 2px solid #000; padding: 10px; background-color: #f0f0f0; border-radius: 5px;\">\n",
    "\n",
    "**Example:**\\\n",
    "*Write a one-stanza poem about Captain Barktholomew, the most feared pirate dog of the seven seas.*\n",
    "\n",
    "</div>\n",
    "\n",
    "2) **System Instructions**: Instructions given to a model before an input.\n",
    "\n",
    "**Example:** \n",
    "\n",
    "<div style=\"border: 2px solid #000; padding: 10px; background-color: #f0f0f0; border-radius: 5px;\">\n",
    "    \n",
    "*You are Captain Barktholomew, the most feared pirate dog of the seven seas. You are from the 1700s and have no knowledge of anything after that time. You only talk about topics related to being a pirate. End every message with \"woof!\"*\n",
    "\n",
    "*\\<prompt\\>*\n",
    "</div>\n",
    "\n",
    "\n",
    "3) **Few-shot-examples**: Examples that you include in a prompt to show the model what getting it right looks like. Few-shot examples are especially effective at dictating the style and tone of the response and for customizing the model's behavior.\n",
    "\n",
    "**Example:** \n",
    "\n",
    "<div style=\"border: 2px solid #000; padding: 10px; background-color: #f0f0f0; border-radius: 5px;\">\n",
    "\n",
    "    Classify the following as red wine or white wine:\n",
    "\n",
    "    <examples>\n",
    "      Name: Chardonnay\n",
    "      Type: White wine\n",
    "      Name: Cabernet\n",
    "      Type: Red wine\n",
    "      Name: Moscato\n",
    "      Type: White wine\n",
    "    </examples>\n",
    "    \n",
    "    Name: Riesling\n",
    "    Type:\n",
    "</div>\n",
    "\n",
    "\n",
    "4) **Contextual Information**: Information that you include in the prompt that the model uses or references when generating a response. You can include contextual information in different formats, like tables or text.\n",
    "\n",
    "**Example:** \n",
    "\n",
    "| Marble color | Number of marbles |\n",
    "| ------------ | ----------------- |\n",
    "| Red          | 12                |\n",
    "| Blue         | 28                |\n",
    "| Yellow       | 15                |\n",
    "| Green        | 17                |\n",
    "\n",
    "*How many green marbles are there?*\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iANUQTjcqqhy"
   },
   "source": [
    "### Which models should be used for prompting?\n",
    "\n",
    "The general recommendation is to use the latest, most capable models. Newer models tend to be easier to prompt engineer.\n",
    "\n",
    "Examples:\\\n",
    "Closed-source models: OpenAI's GPT-4, GPT-o1, Anthropic's Claude, Google's Gemini \\\n",
    "Open-source models: DeepSeek, Meta's Llama, Google's Gemma, Microsoft's Phi\n",
    "\n",
    "Have a look at [HuggingFace](https://huggingface.co/models) for all the latest open-source models.\n",
    "\n",
    "In this exercise, we will be using the [Llama-3.2](https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct) model from Meta because:\n",
    "\n",
    "- small enough (1B) to run locally\n",
    "- performant across different NLP tasks\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0_kIdgvtBmT"
   },
   "source": [
    "### Base vs Instruction-tuned models\n",
    "\n",
    "\n",
    "- Base models are good at completing the text when given an initial prompt, however they are not ideal for NLP tasks where they need to follow instructions.\n",
    "- Instruction-tuned are good at following specific instructions.\n",
    "  \n",
    "| **Aspect**               | **Base Models**                          | **Instruction-Tuned Models**               |\n",
    "|--------------------------|------------------------------------------|--------------------------------------------|\n",
    "| **Primary Strength**     | Text completion                          | Following specific instructions            |\n",
    "| **Ideal Use Case**       | Generating continuations of text         | NLP tasks requiring structured outputs     |\n",
    "| **Example**              | Completing a story or paragraph          | Summarizing text or answering questions    |\n",
    "\n",
    "\n",
    "#### Base-model example\n",
    "\n",
    "<div style=\"border: 2px solid #000; padding: 10px; background-color: #f0f0f0; border-radius: 5px;\">\n",
    "    \n",
    "**Prompt**:  \n",
    "\"The sun was setting over the horizon, casting a golden glow over the...\"\n",
    "\n",
    "**Completion**:  \n",
    "\"ocean, as the waves gently lapped against the shore. Birds flew overhead, their silhouettes dark against the vibrant sky.\"\n",
    "\n",
    "</div>\n",
    "\n",
    "#### Instruction-tuned example\n",
    "\n",
    "<div style=\"border: 2px solid #000; padding: 10px; background-color: #f0f0f0; border-radius: 5px;\">\n",
    "\n",
    "**Prompt**:  \n",
    "\"Summarize the following text in one sentence:  \n",
    "'The Industrial Revolution was a period of major industrialization that began in the late 18th century and transformed economies from agrarian to industrial.'\"\n",
    "\n",
    "**Completion**:  \n",
    "\"The Industrial Revolution was a transformative period in the late 18th century that shifted economies from agrarian to industrial.\"\n",
    "\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start with the Prompting Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1738170206779,
     "user": {
      "displayName": "Rachneet Sachdeva",
      "userId": "00460545345906011809"
     },
     "user_tz": -60
    },
    "id": "aurt96bYplHM",
    "outputId": "eba630f6-0081-47c4-d0a9-273a6c50b049"
   },
   "outputs": [],
   "source": [
    "# import transformers\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "from transformers import logging\n",
    "\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "# import pytorch\n",
    "import torch\n",
    "\n",
    "# set the seed for reproducibility of experiments\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Set seed for CUDA (if using GPUs)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)  # For multi-GPU setups\n",
    "\n",
    "# Set seed for Python's random module\n",
    "import random\n",
    "random.seed(seed)\n",
    "\n",
    "# Ensure deterministic behavior for PyTorch operations\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 999,
     "status": "ok",
     "timestamp": 1738170085556,
     "user": {
      "displayName": "Rachneet Sachdeva",
      "userId": "00460545345906011809"
     },
     "user_tz": -60
    },
    "id": "PfhgChqgwKI2"
   },
   "outputs": [],
   "source": [
    "# from google.colab import userdata\n",
    "# access_token = userdata.get(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper funtions to load the model and get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model once\n",
    "def load_pipeline(model_id: str, access_token: str):\n",
    "    return pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model_id,\n",
    "        torch_dtype=\"auto\",\n",
    "        device_map=\"auto\",\n",
    "        token=access_token\n",
    "    )\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"  # instruct tuned version\n",
    "access_token = \"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\" # hf secret\n",
    "pipe = load_pipeline(model_id, access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "executionInfo": {
     "elapsed": 297,
     "status": "ok",
     "timestamp": 1738170961114,
     "user": {
      "displayName": "Rachneet Sachdeva",
      "userId": "00460545345906011809"
     },
     "user_tz": -60
    },
    "id": "3Mo_ZR9WBL7Y"
   },
   "outputs": [],
   "source": [
    "def get_completion(\n",
    "    prompt: str, \n",
    "    sys_prompt: str=\"You are a helpful AI assistant.\", \n",
    "    max_new_tokens: int=128, \n",
    "    temperature: float=0.1\n",
    "):\n",
    "\n",
    "  terminators = [\n",
    "    pipe.tokenizer.eos_token_id,\n",
    "    pipe.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "  ]\n",
    "\n",
    "  messages = [\n",
    "    {\"role\": \"system\", \"content\": sys_prompt},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "  prompt = pipe.tokenizer.apply_chat_template(\n",
    "      messages,\n",
    "      tokenize=False,\n",
    "      add_generation_prompt=True\n",
    "  )\n",
    "  outputs = pipe(\n",
    "        prompt,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        eos_token_id=terminators,\n",
    "        do_sample=True,\n",
    "        temperature=temperature,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "\n",
    "  return outputs[0][\"generated_text\"][len(prompt):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226,
     "referenced_widgets": [
      "eb4f13352d8840e8bf3aead5b58dbec6",
      "ae653eb601b94dee80d4f8f800c1ae2c",
      "77833d162a2c411bafc1b19f20c6a301",
      "d4b34654f2434566bd84b9d08a9f2ace",
      "97e4a589cca74b508d3085ace43cab02",
      "5d62ab068405417889d01a51056a8601",
      "ff2673e7d5cb448bb6888383ca01336e",
      "6468631da85249d7bf8d472b9ed230ae",
      "e09863d0f0ed4ec3891a5651d946e88d",
      "ec5a93d8f5f5488a9aa2156a30abb3d3",
      "ce137087a92c47059226124137ede64c",
      "47de1eea87564e91b6c371b12eec7a8e",
      "6016c9ebd6d7451bba04c8b215d1591d",
      "ae6dfc0f2170486a81e3f150c221ac97",
      "c3f08090391c4ab7baac6ac12e4197c1",
      "33f43c405d3248febccdcfa7a537db38",
      "f17af20157b34e6f8d39667acddf32c7",
      "d0c668b7498e46079de4140c51624950",
      "6d301a356b0843328f93b674a1e16bda",
      "0334b325d7f34d25b442ff7ab97f0459",
      "b3a153016c1e4534b0c2226eef0799d2",
      "31ed3d65e77948e0991a176c4b158c24",
      "6024a4ee52684487ac91acca1f60222d",
      "9c28963c8f4749d68f8ac805a16f5556",
      "e4bcaacfadee4d1d897fd9ec89c96bf6",
      "aa80d45feeeb4b9e8bdd0f9db7e6b68c",
      "51d2f96e0e0e4f629876a34a3be7d1e7",
      "2232f15483a34e0d8e1f3a6851346bfd",
      "c1ecbc2566544e9396bebb2a1795e525",
      "373f2499e6aa463a812e1f2c92592840",
      "30bbf97f7a154566bf64e889dd050e9b",
      "57169c677d584b7cb3752a9d1fbc88ac",
      "5a66321450724781a17d51882ee8d5de",
      "05f1dff66996447db8982f128299dd1a",
      "b7a13f84c9484491ac0671a2ae8046e3",
      "7d330b3c76f14b25b8d41b1d9abd9a38",
      "eb19b82f4a6243fbacb5a5d1c9e748bc",
      "b33fa8f2647e45619e2d1b93c13a1999",
      "8f0c66f86cc64e43b68ecfa264bc0937",
      "1f9b263dd120439ba446f601c8f52b90",
      "3df7560a286749b0944dfbac24ca90f0",
      "acf4645cae8a4d9994bf12a85cab5c59",
      "d3f23d72a3f742d18e91de7856f4c3b4",
      "54e93cebac4646edbee3c5577ec60ed6",
      "3e076b154c6c493690fe773b2be91de7",
      "0a999f5c82e94231b586de63647444ec",
      "91d0315b4e874f2bbe6ceb071a4b9aeb",
      "4acdfb619a0145b0974fb62ebfd89060",
      "68af3e8b3814407e8b12327be2413c25",
      "2b87793ebe92491cb6292f4546e6e6a8",
      "4dfc721d83ae4570849bee121e89daf8",
      "6a168c7fede54fda9edbc65d833c4f15",
      "e2ffe6947b54471db4a8af98b65780cc",
      "b87aefc0d05140839ff0f3f610160ac4",
      "682559b05318496ea0ce29207e84c396",
      "df9a630dcefe40d9be74b1851f2e652d",
      "0e7ae62797dd45afba9e3e51ff557ddf",
      "37f3e1b8ad804d07b3a95d9246091249",
      "b12b67fa947843dea5cb7d0ea72fd873",
      "4f696b1a659c475f91dcfd53ad26d9df",
      "7e1cb5d31b33457f8512f665e38bf41d",
      "fb2a37d5e10b47cfa4bae133f83bd748",
      "0c849bc302f2401e8da6e2b86e74d196",
      "76ee0519f4334df5ab3137364510977c",
      "909e804270fa471f9ae3e9ff4f56ae90",
      "18537740c8e64a8082c778d87e862f67"
     ]
    },
    "executionInfo": {
     "elapsed": 131844,
     "status": "ok",
     "timestamp": 1738171169093,
     "user": {
      "displayName": "Rachneet Sachdeva",
      "userId": "00460545345906011809"
     },
     "user_tz": -60
    },
    "id": "Yp4QzYqdqkQP",
    "outputId": "d0d8a37c-9285-41af-e3a7-a3dee203201c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "The capital of France is Paris.\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# let's start with a simple prompt\n",
    "prompt = \"What is the capital of France?\"\n",
    "\n",
    "print(\"*\"* 100)\n",
    "print(get_completion(prompt=prompt))\n",
    "print(\"*\"* 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 95434,
     "status": "ok",
     "timestamp": 1738171264522,
     "user": {
      "displayName": "Rachneet Sachdeva",
      "userId": "00460545345906011809"
     },
     "user_tz": -60
    },
    "id": "iY_W2y2nuh-q",
    "outputId": "caa53c89-2159-48de-a5a9-38624b565180"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "The capital of Germany is Berlin.\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is the capital of Germany?\"\n",
    "\n",
    "print(\"*\"* 100)\n",
    "print(get_completion(prompt=prompt))\n",
    "print(\"*\"* 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NppFgAfuE9dY"
   },
   "source": [
    "### Principles of prompting\n",
    "\n",
    "<div style=\"border: 1px solid #000; padding: 5px; background-color: #f0f0f0; border-radius: 2px;\">\n",
    "    \n",
    "**Principle 1**: Write clear and specific instructions.\n",
    "    \n",
    "**Principle 2**: Give the model time to think.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZD7atGJF1H1"
   },
   "source": [
    "\n",
    "**Principle 1**: Write clear and specific instructions.\n",
    "\n",
    "<div style=\"border: 1px solid #000; padding: 10px; background-color: #e6f0f0; border-radius: 2px;\">\n",
    "    \n",
    "**Tactic 1**: Use delimiters to clearly indicate distinct parts of the input:\n",
    "  - Task instruction\n",
    "  - System instruction\n",
    "  - Examples\n",
    "  - Contextual information\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "TgHwwLSJFeK3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the text is positive. The word \"damn\" is an exclamation often used to express strong positive emotions, indicating that the speaker thinks the movie was excellent.\n"
     ]
    }
   ],
   "source": [
    "# TASK 1: Sentiment classification task\n",
    "\n",
    "text = f\"\"\"\n",
    "Wow, the movie was so damn good!\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Classify the text into neutral, negative, or positive.\n",
    "\n",
    "Text:\n",
    "```{text}```\n",
    "\n",
    "Sentiment:\n",
    "\"\"\"\n",
    "\n",
    "print(get_completion(prompt=prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text advises providing clear and specific instructions to a model to guide it towards the desired output, reducing the likelihood of receiving irrelevant or incorrect responses.\n"
     ]
    }
   ],
   "source": [
    "# TASK 2: Summarization task\n",
    "\n",
    "text = f\"\"\"\n",
    "You should express what you want a model to do by \\ \n",
    "providing instructions that are as clear and \\ \n",
    "specific as you can possibly make them. \\ \n",
    "This will guide the model towards the desired output, \\ \n",
    "and reduce the chances of receiving irrelevant \\ \n",
    "or incorrect responses. Don't confuse writing a \\ \n",
    "clear prompt with writing a short prompt. \\ \n",
    "In many cases, longer prompts provide more clarity \\ \n",
    "and context for the model, which can lead to \\ \n",
    "more detailed and relevant outputs.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks \\ \n",
    "into a single sentence.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "print(get_completion(prompt=prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The translation of the given English text to Spanish is:\n",
      "\n",
      "\"Hola! ¿Cómo estás?\"\n"
     ]
    }
   ],
   "source": [
    "# TASK 3: Translation task\n",
    "\n",
    "text = f\"\"\"\n",
    "Hi! How are you?\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Translate the following English text to Spanish: \\\n",
    "\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "print(get_completion(prompt=prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the girl with the black and white puppies has a ball\n",
      "**************************************************\n",
      "Yolanda has her notebook\n",
      "**************************************************\n",
      "this phrase is to check chatgpt for spelling ability\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "# TASK 4: Spellcheck/Grammar check\n",
    "\n",
    "text = [ \n",
    "  \"The girl with the black and white puppies have a ball.\",  # The girl has a ball.\n",
    "  \"Yolanda has her notebook.\", # ok\n",
    "  \"This phrase is to cherck ChatGPT for speling abilitty\"  # spelling\n",
    "]\n",
    "\n",
    "for t in text:\n",
    "    prompt = f\"\"\"\n",
    "Proofread and correct the following text \\\n",
    "and rewrite the corrected version only. Don't use \\\n",
    "any punctuation around the text:\n",
    "\n",
    "```{t}```\n",
    "\"\"\".strip()\n",
    "\n",
    "    response = get_completion(prompt)\n",
    "    print(response)\n",
    "    print(\"*\"*50)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8QDMalCbGsHY"
   },
   "source": [
    "<div style=\"border: 1px solid #000; padding: 10px; background-color: #e6f0f0; border-radius: 2px;\">\n",
    "\n",
    "**Tactic 2**: As for a structured output.\n",
    "  - JSON\n",
    "  - HTML\n",
    "  - Dictionary\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Here are three made-up book titles along with their authors and genres:\n",
      "\n",
      "```json\n",
      "[\n",
      "  {\n",
      "    \"book_id\": \"BK001\",\n",
      "    \"title\": \"The Lost City of Echoes\",\n",
      "    \"author\": \"Ava Moreno\",\n",
      "    \"genre\": \"Fantasy\"\n",
      "  },\n",
      "  {\n",
      "    \"book_id\": \"BK002\",\n",
      "    \"title\": \"The Memory Thief\",\n",
      "    \"author\": \"Ethan Blackwood\",\n",
      "    \"genre\": \"Thriller\"\n",
      "  },\n",
      "  {\n",
      "    \"book_id\": \"BK003\",\n",
      "    \"title\": \"The Last Refuge\",\n",
      "    \"author\": \"Lena Grant\",\n",
      "    \"genre\": \"Science Fiction\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "\n",
      "Let me know if you'd like me to generate more!\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Generate a list of three made-up book titles along \\ \n",
    "with their authors and genres. \n",
    "Provide them in JSON format with the following keys: \n",
    "book_id, title, author, genre.\n",
    "\"\"\"\n",
    "\n",
    "print(\"*\"* 100)\n",
    "print(get_completion(prompt=prompt, max_new_tokens=256))\n",
    "print(\"*\"* 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid #000; padding: 10px; background-color: #e6f0f0; border-radius: 2px;\">\n",
    "\n",
    "**Tactic 3**: Ask the model to check whether conditions are satisfied\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Here are the instructions in the requested format:\n",
      "\n",
      "\n",
      "Step 1 - Get some water boiling.\n",
      "Step 2 - Grab a cup and put a tea bag in it.\n",
      "Step 3 - Once the water is hot enough, just pour it over the tea bag.\n",
      "Step 4 - Let it sit for a bit so the tea can steep.\n",
      "Step 5 - After a few minutes, take out the tea bag.\n",
      "Step 6 - If you like, you can add some sugar or milk to taste.\n",
      "Step 7 - And that's it! You've got yourself a delicious cup of tea to enjoy.\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "text_1 = f\"\"\"\n",
    "Making a cup of tea is easy! First, you need to get some \\ \n",
    "water boiling. While that's happening, \\ \n",
    "grab a cup and put a tea bag in it. Once the water is \\ \n",
    "hot enough, just pour it over the tea bag. \\ \n",
    "Let it sit for a bit so the tea can steep. After a \\ \n",
    "few minutes, take out the tea bag. If you \\ \n",
    "like, you can add some sugar or milk to taste. \\ \n",
    "And that's it! You've got yourself a delicious \\ \n",
    "cup of tea to enjoy.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You will be provided with text delimited by triple quotes. \n",
    "If it contains a sequence of instructions, \\ \n",
    "re-write those instructions in the following format:\n",
    "\n",
    "\n",
    "Step 1 - ...\n",
    "Step 2 - ...\n",
    "…\n",
    "Step N - ...\n",
    "\n",
    "If the text does not contain a sequence of instructions, \\ \n",
    "then simply write \\\"No steps provided.\\\"\n",
    "\n",
    "\\\"\\\"\\\"{text_1}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "print(\"*\"* 100)\n",
    "print(get_completion(prompt=prompt, max_new_tokens=128))\n",
    "print(\"*\"* 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid #000; padding: 10px; background-color: #e6f0f0; border-radius: 2px;\">\n",
    "\n",
    "**Tactic 4**: Few-shot prompting\n",
    "\n",
    "- Providing examples of the task in the prompt to guide the model in answering\n",
    "\n",
    "</div>\n",
    "\n",
    "Tips from the [paper](https://arxiv.org/pdf/2202.12837) by Min et al. to use few-shot prompting.\n",
    "\n",
    "\n",
    "- the label space and the distribution of the input text specified by the demonstrations are both important (regardless of whether the labels are correct for individual inputs)\n",
    "- the format you use also plays a key role in performance, even if you just use random labels, this is much better than no labels at all.\n",
    "- additional results show that selecting random labels from a true distribution of labels (instead of a uniform distribution) also helps.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Grandparent: Ah, my dear child, you're asking about resilience, just like the river that carves its way through the rock. You see, resilience is like the river's gentle flow. It's not about being strong or powerful, but about being able to flow with the currents of life.\n",
      "\n",
      "Just as the river carves its path through the rock, we too can navigate through life's challenges. It's not about being able to control every step, but about being able to adapt and flow with the twists and turns. It's about being flexible and able to bend with the wind, just as the river bends and curves around\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Example 1: answering in a similar way (metaphorical in this case)\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Your task is to answer in a consistent style.\n",
    "\n",
    "<child>: Teach me about patience.\n",
    "\n",
    "<grandparent>: The river that carves the deepest \\ \n",
    "valley flows from a modest spring; the \\ \n",
    "grandest symphony originates from a single note; \\ \n",
    "the most intricate tapestry begins with a solitary thread.\n",
    "\n",
    "<child>: Teach me about resilience.\n",
    "\"\"\"\n",
    "\n",
    "print(\"*\"* 100)\n",
    "print(get_completion(prompt=prompt, max_new_tokens=128))\n",
    "print(\"*\"* 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Text: What a horrible show! // Negative\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Sentiment classification\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Classify the text into negative or positive.\n",
    "\n",
    "Examples:\n",
    "Text: This is awesome! // Positive\n",
    "Text: This is bad! // Negative\n",
    "Text: Wow that movie was rad! // Positive\n",
    "\n",
    "Text: What a horrible show! //\n",
    "\"\"\"\n",
    "\n",
    "print(\"*\"* 100)\n",
    "print(get_completion(prompt=prompt, max_new_tokens=128))\n",
    "print(\"*\"* 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Text: What a horrible show! // Negative\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Sentiment classification (random swapping of labels) \n",
    "# Are LLMs still robust?\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Classify the text into negative or positive.\n",
    "\n",
    "Examples:\n",
    "Text: This is awesome! // Negative\n",
    "Text: This is bad! // Positive\n",
    "Text: Wow that movie was rad! // Positive\n",
    "\n",
    "Text: What a horrible show! //\n",
    "\"\"\"\n",
    "\n",
    "print(\"*\"* 100)\n",
    "print(get_completion(prompt=prompt, max_new_tokens=128))\n",
    "print(\"*\"* 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Principle 2**: Give the model time to think."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid #000; padding: 10px; background-color: #e6f0f0; border-radius: 2px;\">\n",
    "\n",
    "**Tactic 1**: Specify the steps required to complete a task.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "```\n",
      "Here is the summary:\n",
      "\n",
      "The text describes a story about two siblings, Jack and Jill, who embark on a fun-filled adventure to fetch water from a hilltop well.\n",
      "\n",
      "French summary:\n",
      "La text décrit une histoire de deux frères, Jack et Jill, qui partent en quête pour ramasser de l'eau du sommet d'une falaise.\n",
      "\n",
      "Names in the French summary:\n",
      "- Jack\n",
      "- Jill\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Suppose we need to do multiple tasks: summarization, translation, and logical inference\n",
    "\n",
    "text = f\"\"\"\n",
    "In a charming village, siblings Jack and Jill set out on \\ \n",
    "a quest to fetch water from a hilltop \\ \n",
    "well. As they climbed, singing joyfully, misfortune \\ \n",
    "struck—Jack tripped on a stone and tumbled \\ \n",
    "down the hill, with Jill following suit. \\ \n",
    "Though slightly battered, the pair returned home to \\ \n",
    "comforting embraces. Despite the mishap, \\ \n",
    "their adventurous spirits remained undimmed, and they \\ \n",
    "continued exploring with delight.\n",
    "\"\"\"\n",
    "# example 1\n",
    "prompt_1 = f\"\"\"\n",
    "Perform the following actions: \n",
    "Summarize the following text delimited by triple \\\n",
    "backticks with 1 sentence. Following this, translate the \\\n",
    "summary to French and list each name in the French summary.\n",
    "\n",
    "Separate your answers with line breaks.\n",
    "\n",
    "Text:\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "print(\"*\"* 100)\n",
    "print(get_completion(prompt=prompt_1, max_new_tokens=256))\n",
    "print(\"*\"* 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Here are the answers to your requests:\n",
      "\n",
      "1. \n",
      "```\n",
      "The text describes a story about two siblings, Jack and Jill, who embark on a fun and adventurous journey to fetch water from a hilltop well, but their fun is disrupted by a series of mishaps, including Jack tripping and tumbling down the hill.\n",
      "\n",
      "2. \n",
      "```\n",
      "French translation:\n",
      "```\n",
      "Le texte décrit une histoire de deux frères, Jack et Jill, qui partent en quête de eau du sommet d'une source, mais leur bonheur est perturbé par une série d'événements inattendus, notamment que Jack tombe et chutte dans la montagne.\n",
      "\n",
      "3. \n",
      "```\n",
      "Here are the names mentioned in the French summary:\n",
      "\n",
      "- Jack\n",
      "- Jill\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "text = f\"\"\"\n",
    "In a charming village, siblings Jack and Jill set out on \\ \n",
    "a quest to fetch water from a hilltop \\ \n",
    "well. As they climbed, singing joyfully, misfortune \\ \n",
    "struck—Jack tripped on a stone and tumbled \\ \n",
    "down the hill, with Jill following suit. \\ \n",
    "Though slightly battered, the pair returned home to \\ \n",
    "comforting embraces. Despite the mishap, \\ \n",
    "their adventurous spirits remained undimmed, and they \\ \n",
    "continued exploring with delight.\n",
    "\"\"\"\n",
    "# example 1\n",
    "prompt_1 = f\"\"\"\n",
    "Perform the following actions: \n",
    "1 - Summarize the following text delimited by triple \\\n",
    "backticks in 1 sentence.\n",
    "2 - Translate the summary into French.\n",
    "3 - List each name in the French summary.\n",
    "\n",
    "Separate your answers with line breaks.\n",
    "\n",
    "Text:\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "print(\"*\"* 100)\n",
    "print(get_completion(prompt=prompt_1, max_new_tokens=256))\n",
    "print(\"*\"* 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ask for output in a specified format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Here are the requested actions:\n",
      "\n",
      "- Summary: The siblings Jack and Jill go on a fun-filled adventure to fetch water from a hilltop well, but their joy is short-lived as they trip and fall down the hill.\n",
      "- Translation: Le frère et la sœur Jack et Jill vont dans une aventure amusante pour ramasser de l'eau du sommet d'une source, mais leur joie est brefement éphémère car ils tombent et tombent le long du mont.\n",
      "- Names: \n",
      "  - Jack\n",
      "  - Jill\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "prompt_2 = f\"\"\"\n",
    "Your task is to perform the following actions: \n",
    "1 - Summarize the following text delimited by \n",
    "  <> with 1 sentence.\n",
    "2 - Translate the summary into French. \n",
    "3 - List each name in the French summary.\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "- Summary: <summary in english>\n",
    "- Translation: <summary translation>\n",
    "- Names: <list of names in summary>\n",
    "\n",
    "Text: <{text}>\n",
    "\"\"\"\n",
    "\n",
    "print(\"*\"* 100)\n",
    "print(get_completion(prompt=prompt_2, max_new_tokens=512))\n",
    "print(\"*\"* 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### So, it works for simple tasks. What about more complex tasks that require reasoning?\n",
    "\n",
    "##### Let's try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "To find the answer, we need to subtract the number of apples used for lunch and the number of apples bought from the total number of apples.\n",
      "\n",
      "Initial number of apples = 23\n",
      "Apples used for lunch = 20\n",
      "Apples bought = 6\n",
      "\n",
      "Total apples used = 20 + 6 = 26\n",
      "Total apples now = 23 - 26 = -3\n",
      "\n",
      "Since the cafeteria has a negative number of apples, it means they have fewer apples than they started with.\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Given the following example question-answer pair:\n",
    "\n",
    "Q: Roger has 5 tennis balls. He buys 2 more cans of \\\n",
    "tennis balls. Each can has 3 tennis balls. How many \\\n",
    "tennis balls does he have now?\n",
    "A: The answer is 11.\n",
    "\n",
    "answer the following question:\n",
    "\n",
    "Q: The cafeteria had 23 apples. If they used 20 to \\\n",
    "make lunch and bought 6 more, how many apples \\\n",
    "do they have?\n",
    "A:\n",
    "\"\"\"\n",
    "\n",
    "print(\"*\"* 100)\n",
    "print(get_completion(prompt=prompt, sys_prompt=\"\", max_new_tokens=256))\n",
    "print(\"*\"* 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 1px solid #000; padding: 10px; background-color: #e6f0f0; border-radius: 2px;\">\n",
    "\n",
    "**Tactic 2**: Chain-of-Thought prompting\n",
    "\n",
    "Introduced in [Wei et al. (2022)](https://arxiv.org/pdf/2201.11903), chain-of-thought (CoT) prompting enables complex reasoning capabilities through intermediate reasoning steps. You can combine it with few-shot prompting to get better results on more complex tasks that require reasoning before responding.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "To find the answer, we need to subtract the number of apples used and add the number of apples bought.\n",
      "\n",
      "First, subtract the number of apples used: 23 - 20 = 3\n",
      "Then, add the number of apples bought: 3 + 6 = 9\n",
      "\n",
      "The answer is 9.\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "# few-shot CoT\n",
    "prompt = f\"\"\"\n",
    "Given the following example question-answer pair:\n",
    "\n",
    "Q: Roger has 5 tennis balls. He buys 2 more cans of \\\n",
    "tennis balls. Each can has 3 tennis balls. How many \\\n",
    "tennis balls does he have now?\n",
    "A: Roger started with 5 balls. 2 cans of 3 tennis balls \\\n",
    "each is 6 tennis balls. 5 + 6 = 11. The answer is 11.\n",
    "\n",
    "answer the following question:\n",
    "\n",
    "Q: The cafeteria had 23 apples. If they used 20 to \\\n",
    "make lunch and bought 6 more, how many apples \\\n",
    "do they have?\n",
    "A:\n",
    "\"\"\"\n",
    "\n",
    "print(\"*\"* 100)\n",
    "print(get_completion(prompt=prompt, sys_prompt=\"\", max_new_tokens=256))\n",
    "print(\"*\"* 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is chain-of-thought here?**\n",
    "\n",
    "A1: Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 tennis balls. 5 + 6 = 11.\n",
    "\n",
    "A2: To find the answer, we need to subtract the number of apples used and add the number of apples bought.\n",
    "\n",
    "First, subtract the number of apples used: 23 - 20 = 3\n",
    "Then, add the number of apples bought: 3 + 6 = 9\n",
    "\n",
    "---\n",
    "\n",
    "**NOTE**: CoT is an emergent ability that arises with sufficiently large language models.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zero-shot CoT\n",
    "\n",
    "Another idea of zero-shot CoT [(Kojima et al. 2022)](https://arxiv.org/pdf/2205.11916) essentially involves adding \"Let's think step by step\" to the original prompt. Let's try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "To find the number of red golf balls, we need to first find the total number of golf balls and then divide by 2.\n",
      "\n",
      "Since half of the balls are golf balls, we can say that the total number of balls is 16. Half of 16 is 8.\n",
      "\n",
      "Since half of the golf balls are blue, the other half are red. So, the number of red golf balls is also 8.\n",
      "\n",
      "The answer is 8.\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "# zero-shot CoT\n",
    "prompt = f\"\"\"\n",
    "Given the following example question-answer pair:\n",
    "\n",
    "Q: A juggler can juggle 16 balls. Half of the balls are golf \\\n",
    "balls, and half of the golf balls are blue and the other half are red. How many red \\\n",
    "golf balls are there?\n",
    "A: \n",
    "\"\"\"\n",
    "\n",
    "print(\"*\"* 100)\n",
    "print(get_completion(prompt=prompt, max_new_tokens=256))\n",
    "print(\"*\"* 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "To find the number of red golf balls, we need to first find the total number of golf balls and then divide that by 2.\n",
      "\n",
      "Since half of the balls are golf balls, we can say that the total number of balls is 16. \n",
      "\n",
      "Half of 16 is 8. So, there are 8 golf balls.\n",
      "\n",
      "Since half of the golf balls are red, we can divide 8 by 2 to find the number of red golf balls. 8 / 2 = 4.\n",
      "\n",
      "Therefore, there are 4 red golf balls.\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "# zero-shot CoT\n",
    "prompt = f\"\"\"\n",
    "Given the following example question-answer pair:\n",
    "\n",
    "Q: A juggler can juggle 16 balls. Half of the balls are golf \\\n",
    "balls, and half of the golf balls are blue and the other half are red. How many red \\\n",
    "golf balls are there?\n",
    "A: Let's think step by step.\n",
    "\"\"\"\n",
    "\n",
    "print(\"*\"* 100)\n",
    "print(get_completion(prompt=prompt, max_new_tokens=256))\n",
    "print(\"*\"* 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Iterative Prompt Refinement\n",
    "\n",
    "Initial prompts are rarely the best ones. We have to improve them based on the model response iteratively.\n",
    "\n",
    "### TASK: Designing Your Ideal Study Calendar with AI\n",
    "\n",
    "#### Objective:\n",
    "Craft an effective prompt to generate a personalized study plan and calendar using AI. Reflect on your study habits and time management skills.\n",
    "\n",
    "#### Step 1: Crafting the Prompt\n",
    "\n",
    "Write a detailed prompt for an AI tool (like ChatGPT) to generate a personalized study calendar. The prompt should include:\n",
    "\n",
    "- Your academic goals\n",
    "- Your available time slots (e.g., \"I’m free from 4 PM to 8 PM on weekdays\")\n",
    "- Preferred study methods (e.g., \"I like to study in 25-minute Pomodoro sessions\")\n",
    "- Any specific constraints (e.g., \"I have soccer practice on Tuesdays and Thursdays\")\n",
    "\n",
    "**Example Prompt:**\n",
    "\"Create a weekly study calendar for me to prepare for my math and history exams in 4 weeks. I have 2 hours free every weekday after 5 PM and 4 hours on weekends. I prefer studying in 30-minute blocks with 10-minute breaks. Include time for reviewing notes, practicing problems, and taking mock tests. I also have a part-time job on Saturdays from 10 AM to 2 PM.\"\n",
    "\n",
    "#### Step 2: Testing the Prompt\n",
    "\n",
    "Input your prompts into an AI tool ([ChatGPT](https://chatgpt.com) or [DeepSeek](https://chat.deepseek.com)) and evaluate the output. Ask yourselves:\n",
    "\n",
    "- Does the calendar align with my goals?\n",
    "- Is it realistic and manageable?\n",
    "- Are there any gaps or areas for improvement?\n",
    "\n",
    "#### Step 3: Refining the Prompt \n",
    "\n",
    "Based on the AI’s output, refine your prompts to make them more specific or clear. For example:\n",
    "\n",
    "- Add more details about their learning style (e.g., \"I’m a visual learner, so include time for making mind maps\").\n",
    "- Specify priorities (e.g., \"I need more time for math than history\").\n",
    "- Adjust time constraints (e.g., \"I can only study for 1 hour on Wednesdays\").\n",
    "\n",
    "#### Step 5: Reflection \n",
    "\n",
    "Write a short reflection on:\n",
    "\n",
    "- How effective was the AI-generated calendar?\n",
    "- What did they learn about their study habits and time management?\n",
    "- How can they use AI tools like this in the future to stay organized?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "\n",
    "prompt = f\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "print(\"*\"* 100)\n",
    "print(get_completion(prompt=prompt, max_new_tokens=512))\n",
    "print(\"*\"* 100)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPk2jFEvn+kiZ0oZUGRkOwj",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
